在很多视频的处理中，经常需要追踪某个物体在这段视频中的变化，很多时候追踪这个物体全部特征比较困难，但如果只追踪这个物体的一些关键的点，就会比较简单。

比如海洋中生活着很多种章鱼，而章鱼有个特性会经常改变自己的形状，很多章鱼都会把自己的身体变扁或者变细，以钻进一些细小的石缝内。对于生物学家来说，要确定章鱼的大小就比较困难了，后来生物学家发现了一个规律，章鱼虽然经常改变自己身体的大小和形状，但章鱼两个眼睛的距离确实比较恒定的，因此生物学家经常把章鱼两个眼睛之间的距离作为章鱼体型大小的数据。

回到编程来，如果有段有关章鱼的纪录片视频，现在需要分析这些章鱼在视频中的位置，行动习惯等等，那么追踪章鱼的两个眼睛比追踪章鱼的整体要简单许多。

## 角点与亚像素点

对于一个物体的关键点来说，根据不同的需求有不同的算法来查找，不同的算法查找出来的关键点也有所不同，opencv提供goodFeaturesToTrack()来查找关键点，定义如下
```c++
void goodFeaturesToTrack(InputArray image, 
                         OutputArray corners,
                        int maxCorners, 
                        double qualityLevel, 
                        double minDistance,
                        InputArray mask = noArray(), 
                        int blockSize = 3,        
                        bool useHarrisDetector = false, 
                        double k = 0.04 );
```
参数image是查找的目标图片，该图片必须是8位或者32位的单通道图片

参数corners是查询的结果，通常使用std::vector < cv::Point2f >。

参数maxCorners是查询关键点的最大个数

参数qualityLevel用于设置关键点的返回质量，通常取值[0.01,0.1]

参数minDistance用于设置关键点之间的距离，当查找到一个关键点时，便不在该范围内再寻找

参数mask为掩码

参数blockSize用于表示查询关键点时需要考虑的区域大小，对于高精度图片，这个值可以适当调大

参数useHarrisDetector用于设置查询关键点的算法，默认使用哈尔角点算法，该算法由Shi和Tomasi共同提出，也称Shi-Tomasi算法，用此算法查找到的关键点也称为角点，如果该值设为true，则使用哈尔原始算法的精确角点强度公式。

参数k只在使用哈尔角点算法时有效，一般使用默认值即可

goodFeaturesToTrack()可以有效的寻找图片中的关键点，但这里有个问题，该函数查找的是某个元素，但很多物体的特征点不会位于一个元素内，比如之前提过的章鱼的眼睛，在一幅图片内，章鱼的眼睛可能占据多个元素的位置，假如章鱼的眼睛占据16个元素，既一个4x4的矩阵，此时需要眼睛中心作为关键点，那这个关键点就会位于两个元素的中间。为了解决这个问题，opencv提供了亚元素角点的概念，既首先寻找关键区域的角点，然后以角点和周围的元素进行一定的计算，进而确定关键点，通过这种方式确定的关键点被称为亚像素角点，opencv提供了cornerSubPix()函数来实现该功能
```c++
void cornerSubPix(InputArray image, 
                  InputOutputArray corners,
                  Size winSize, 
                  Size zeroZone,
                  TermCriteria criteria );
```
参数image是目标图片

参数corners是查询到的全部亚像素角点

参数winSize是要求计算的区域，一个亚像素角点会在该区域内计算得出

参数zeroZone用于标注忽略的区域，该区域通常比winSize小一些，如果指定了该值，计算时先查找到角点，然后忽略角点附近区域的元素（大小为zeroZone）。如果不想由此步骤，传入Size(-1,-1)即可

最后的TermCriteria是一个稍显复杂的类，其完整定义如下
```c++
class TermCriteria{
public:
    enum Type{
        COUNT=1, 
        MAX_ITER=COUNT, 
        EPS=2 
    };

    TermCriteria();
    TermCriteria(int type, int maxCount, double epsilon);

    inline bool isValid() const{
        const bool isCount = (type & COUNT) && maxCount > 0;
        const bool isEps = (type & EPS) && !cvIsNaN(epsilon);
        return isCount || isEps;
    }

    int type; 
    int maxCount; 
    double epsilon; 
};
```
这个类在opencv的很多函数里都会作为参数使用，该类主要用于设置算法的迭代次数和精度。

类成员type的值为枚举值，既类内枚举Type,该值用于设置，该类是用于限制迭代次数还是精度，或者同时限定

类成员maxCount用于设置迭代次数

参数epsilon用于设置算法的精度

## 光流和金字塔算法

对于一段视频来说，如果要分析一个物体持续的变换，就需要逐帧分析。而光流便是指在连续的两帧，每个对应位置的变化。光流分为稠密和稀疏，稠密光流指的是分析两帧图片的全部像素，这导致计算量会非常大，而稀疏光流则仅分析关注的部分的元素。比如一张包含章鱼的图片，仅分析眼睛部分。

在光流分析中，一个很常见的问题便是两帧之间变化过大，很多相机每秒拍摄24帧，如果有高速变化的物体，比如炸开的烟花，那在两帧画面内，该物体的形状可能发生比较大的变化，要准确的追踪这样变化比较大的物体，一个解决方案就是扩大追踪范围，但扩大追踪范围又会导致追踪的困难，为此需要采用一种称为金字塔算法（全称：金字塔Lucas-Kanade光流）的方案，该方案的基本思路是先追踪一帧图片中的某个关键点，然后以此为中心逐渐扩大追踪范围，从上到下类似于金字塔结构，opencv中提供了calcOpticalFlowPyrLK()函数来实现金字塔算法,定义如下
```c++
void calcOpticalFlowPyrLK(InputArray prevImg, 
                          InputArray nextImg,
                          InputArray prevPts, 
                          InputOutputArray nextPts,
                          OutputArray status, 
                          OutputArray err,
                          Size winSize = Size(21,21), 
                          int maxLevel = 3,
                          TermCriteria criteria = TermCriteria(TermCriteria::COUNT+TermCriteria::EPS, 30, 0.01),
                          int flags = 0, 
                          double minEigThreshold = 1e-4 );
```
参数prevImg和nextImg表示两帧图片，通常是视频中连续的两帧

参数prevPts表示需要追踪的关键点，这些点通常在prevImg中找到

参数nextPts是输出结果，也就是prevImg中的prevPts在nextImg出现的位置

参数status和err通常是一个vector < uchar >,对于prevPts[i]来说，如果该点在prevPts中被追踪到，则status[i]的对应索引的值为非0，否则为0；err[i]则是该点在prevPts被找到后的错误度量，如果点未被找到，则err[i]不定义

参数maxLevel用于设置金字塔的深度，如果该值为0，则不使用金字塔算法

参数criteria之前介绍过，用于控制函数计算的类型以及迭代次数等等

参数flags是个枚举值，有2个值，可以取其一也可以一起设置
| 枚举值 | 含义 |
| ---- | ---- |
| cv::OPTFLOW_LK_GET_MIN_EIGENVALS | 用于获得更详细的错误度量 |
| cv::OPTFLOW_USE_INITIAL_FLOW | nextPts中是否包含特征坐标的初始估计 |

参数minEigThreshold用于滤过，过滤掉不需要的关键点

接下来用一段示例演示下角点以及光流追踪
```c++
int main() {
    //该视频是opencv自带的视频，在“背景”章节中也使用过
	cv::VideoCapture video;
	if (!video.open("E:/BackGround/tree.avi")) {
		std::cout << "视频无法打开";
		return 0;
	}
	cv::Mat mat_0, mat_1; //取视频的前两帧作为比较
	video.read(mat_0);
	video.read(mat_1);
	cv::cvtColor(mat_0, mat_0, cv::COLOR_BGR2GRAY);
	cv::cvtColor(mat_1, mat_1, cv::COLOR_BGR2GRAY);

	std::vector<cv::Point2f> conner_points;
    //使用Shi-Tomasi算法查找角点，这里查找100个
	cv::goodFeaturesToTrack(mat_0, conner_points, 100, 0.05, 5, cv::noArray());

	std::vector<uchar> track_res;
	std::vector<cv::Point2f> track_points;
	cv::calcOpticalFlowPyrLK(mat_0, mat_1, conner_points, track_points, track_res, cv::noArray());

	for (std::size_t i = 0; i < track_res.size(); ++i) {
		if (track_res.at(i) == 0)
			continue;
        //采用黑线绘制，并且黑线使用较粗的4，这样方便观察结果
		cv::line(mat_1, conner_points.at(i), track_points.at(i), cv::Scalar(0, 0, 0),4);
	}

	cv::imshow("第一帧", mat_0);
	cv::imshow("第二帧", mat_1);
	cv::waitKey();
	cv::destroyAllWindows();
}
```

运行结果

![图1](https://jxf2008-1302581379.cos.ap-nanjing.myqcloud.com/github_blog/opencv/keypoint_1.png)
