在安防领域，有一个常见的需求，当一个物体进入摄像头的范围内，相关软件必须识别出有物体进入。从视频中提取出两帧，其中一帧多了一个物体，比如一辆刚驶入画面的汽车，通常，最大的麻烦不少对驶入的汽车的识别，而是一直存在于画面的背景的干扰。

关于背景和前景，一般来说，背景是一直存在于画面中的物体，比如一棵树，一面墙，而这些物体是需要忽略的，而前景则是被关注的部分。在图像分析中，这两者之间没有绝对的区别，而其中最重要的就是消除背景的影响。比如一个对着大门的摄像头，范围内有一棵柳树，在较大风的情况下，树枝的摇动会导致树枝出现在屏幕的大部分，而这个摄像头的任务是识别是否有车辆进入大门，那么软件要根据画面判断是否有物体在移动（驶入的汽车）就变的非常麻烦。

背景的消除有很多方法，但背景处理的实际情况非常多且具有不确定性，比如某个对着一段围墙的摄像头，本职任务是监测是否有人翻墙入内，该摄像头检测到墙的边缘有物体移动时就会发出通知，结果附近的狸花猫在墙上走过时每次都会导致摄像头误判。因此，对于背景的消除识别与前景的提取需要根据实际情况选择不同的方法或者学习模型，而不存在一直普遍适合的方案。

## 帧间差分

帧间差分是一种简单，实用的方法，当然缺点也很明显。帧间差分的基本原理就是比较两帧，将这两帧的每个对应的元素相减，如果有物体进入画面内，这回导致这个位置的元素，在两帧画面内差距非常大，根据这个原理很容易将进入画面的物体识别出来，opencv提供了函数用于将两个画面相减
```c++
void absdiff(InputArray src1, InputArray src2, OutputArray dst);
```
参数src1和src2是对应的两帧画面，参数dst是两帧相减的结果

下面是用手机在相同位置拍摄的画面，一个画面上有一个耳机，另一个没有。这刚好可以看出一个视频的两帧，一帧有物体进入，而另一种没有。手机拍摄位于相同的位置，但两次拍摄因为是手拿手机，因此拍摄位置不是绝对相同，这和实际的安防摄像头类似，大风，来往车辆震动等会导致摄像头有一定的微调。
```c++
    cv::Mat mat_background1 = cv::imread("E:/BackGround/background1.png");
	cv::Mat mat_background2 = cv::imread("E:/BackGround/background2.png");
	cv::Mat mat_dst;

	cv::cvtColor(mat_background1, mat_background1, CV_8UC1);
	cv::cvtColor(mat_background2, mat_background2, CV_8UC1);

	cv::absdiff(mat_background1, mat_background2, mat_dst);
    //对比结果，如果差距过大，比如大于100，就认为是进入的物体导致的
	cv::threshold(mat_dst,mat_dst, 100, 255, cv::THRESH_BINARY);

	cv::imshow("图一", mat_background1);
	cv::imshow("图二", mat_background2);
	cv::imshow("对比结果", mat_dst);
```
运行结果
![图1](https://jxf2008-1302581379.cos.ap-nanjing.myqcloud.com/github_blog/opencv/background_1.png)

这里可以看出帧间差分很准确的找出了耳机，并且消除了绝大部分的背景。但帧间差分的缺点也很明显，图中耳机放在桌子上，而桌子上有一条细缝，这属于尖锐的噪声，而由于拍摄的位置并不是完全一致，这导致这些尖锐的噪声在两帧里的位置有所偏移，帧间差分就会把这种尖锐的噪声识别为进入画面的物体，而实际情况中，这种尖锐的噪声是非常常见的现象。

## 平均背景法

消除背景的另一个常见的方法是均背景法，这个方法需要一定量的样本，并建立一个学习模型。基本的思路是这样的，对于一个画面，其中很多背景存在一定的变化，但变化的量是有限的，比如墙壁的颜色在正午和傍晚会有所不同，但变化不会太大，因此如有足够的样本统计墙的颜色变化，那当由物体进入墙范围，导致墙的部分颜色发生改变时，就可以通过模型判断，如果变化没有超过样本的范围，可以认为是正常变化，如果变化范围超过了之前模型统计的范围，那就可以认为是有物体进入了。

为了统计样本，需要建立一个简单的学习模型，如下
```c++
//这个模型根据不同的视频长度和硬件，执行的时间可能会有较大的差别，以我的电脑为例，一段10秒的视频，需要超过3分钟才能全部运行完成
class BackGroundStudy {
private:
	float thres_high;  //标记背景变化范围，超过该范围的属于别的物体进入
	float thres_low;
	std::vector<cv::Mat> all_mats;
	std::vector<cv::Mat> high_channls; //全部通道的变化上限
	std::vector<cv::Mat> low_channls;  //全部通道的变化下线
	cv::Mat mat_avg;
	cv::Mat mat_diff;
public:
	BackGroundStudy();
	~BackGroundStudy();
	cv::Mat set_data(const std::string video_str, float high = 5.f, float low = 5.f, std::size_t index = 0;);
	void show_diff(const cv::Mat& src, cv::Mat& diff);
	void training();
};
```
该类构造函数和析构函数使用默认即可。set_data()函数用于设置模型训练需要的一些数据
```c++
cv::Mat BackGroundStudy::set_data(const std::string video_str, float high, float low, std::size_t index) {
	all_mats.clear();
    //设置背景变化，上限和下线默认值都是5
	thres_high = high;
	thres_low = low;

	cv::VideoCapture video;
	if (video.open(video_str))
		std::cout << "视频加载成功" << std::endl;
	else {
		std::cout << "视频加载失败" << std::endl;
		std::abort();
	}

	cv::Mat tmp,v;
	while (video.read(tmp)) {
        //因为稍后计算的需要，这里要把全部图片数据类型转化为64位浮点，这步可能很耗时间
		tmp.convertTo(v, CV_64F, 1.0 / 255.0);
		all_mats.push_back(v);
	}

	std::cout << "已经成功载入视频中的" << all_mats.size() << "帧图片" << std::endl;

	cv::Size size = all_mats[0].size();
	mat_avg = cv::Mat::zeros(size, CV_64FC3);
	mat_diff = cv::Mat::zeros(size, CV_64FC3);

    //返回视频任意一帧图片，学习完成后可以使用这帧图片和学习数据对比，看是否有物体进入
	return all_mats[index];
}
```
接下来是training()函数
```c++
void BackGroundStudy::training() {
	cv::Mat tmp, mat_prev;
	std::size_t cs = all_mats.size();
	for (std::size_t i = 0; i < cs; ++i) {
        //将全部图片累加
		mat_avg += all_mats[i];

		if (i != 0) {
            //将图片的差值累加
			cv::absdiff(mat_prev, all_mats[i], tmp);
			mat_diff += tmp;
		}
		mat_prev = all_mats[i];
	}

    //计算出全部图片的平均值和全部差值的平均值
	mat_avg /= static_cast<float>(cs);
	mat_diff /= static_cast<float>(cs - 1);

    //设置范围，平均值+平均差x权重 为变化的上限
    //平均值-平均差x权重 为变化的下线
	mat_high = mat_avg + mat_diff * thres_high;
	mat_low = mat_avg - mat_diff * thres_low;

    //将上下限每个通道单独保存，如果一帧画面中，一个通道的部分元素变化过大，就可以认为有物体进入
	cv::split(mat_high, high_channls);
	cv::split(mat_low, low_channls);
}
```
training()函数的原理很简单，就是先求全部样本的平均值，再把每帧图片的差值相加并求得平均差值，然后根据权重计算得到变化的上下限。这里有个细节，计算平均值的时候需要用到Mat除以数量，由于我的编译器是64位的，因此在set_data()函数中将图片的全部数据类型转换成了CV_64F，如果你用的是32位编译器，也可以把图全部设置位CV_32F。

最后是对比函数，将图片和训练后比较
```c++
void BackGroundStudy::show_diff(const cv::Mat& src, cv::Mat& diff) {
	std::vector<cv::Mat> src_channls;
	cv::split(src, src_channls);

	cv::Mat tmp;
	cv::inRange(src_channls[0], high_channls[0], low_channls[0], diff);
	cv::inRange(src_channls[1], high_channls[1], low_channls[1], tmp);
	diff = cv::min(tmp, diff);
	cv::inRange(src_channls[2], high_channls[2], low_channls[2], tmp);
	diff = cv::min(tmp, diff);
}
```
这个函数将输入图片src的三个通道和学习后的样本逐一对比，超过范围的元素就设置为255，三次对比后三个通道所有超过范围的元素都会显示在参数diff上。

